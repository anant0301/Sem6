{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set IV - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select a subset of relevant attributes from the given dataset that are necessary to know about thetotal volume of avocados with product lookup codes (PLU) 4046, 4225, 4770) which are of organic type. (Use AVOCADO dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Discard all duplicate entries in the given dataset and fill all the missing values in the attribute “AveragePrice” as 1.25. Also print the size of the dataset before and after removing duplicates. (Use Trail dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Binarize the attribute “Year”. Set the threshold above 2016 and print it without truncation. (Use AVOCADO dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Transform all categorical attributes in the dataset AVOCADO using Integer Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Transform the attribute = “Region” in the given dataset AVOCADO using One-Hot Encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Ignore the tuples that hold missing values and print the subset of data from AVOCADO dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Drop the attribute that has high nullity as it facilitates efficient prediction. (Use AVOCADO dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Study the entire dataset and report the complete statistical summary about the data (Use AVOCADO\n",
    "    dataset)\n",
    "    • Dimension of the dataset\n",
    "    • Most frequently occurring value under every attribute.\n",
    "    • Datatype of every attribute\n",
    "    • Count\n",
    "    • Mean\n",
    "    • Standard Deviation\n",
    "    • Minimum Value\n",
    "    • Maximum value\n",
    "    • 25% (Lower Quartile)\n",
    "    • Median i.e. 50%\n",
    "    • 75% (Upper Quartile)\n",
    "    • Find whether the class distribution of dataset is imbalanced. (Note: Fix the class label as “Type” in the given dataset)\n",
    "    • Correlation matrix\n",
    "    • Skewness of every attribute.\n",
    "    (For the below exercises, you are free to choose an appropriate data set as merited by the problem statements)\n",
    "9. Test drive the use of Gini Index, Information Gain, Entropy and other measures that are supported in your platform, performing the role of data selection.\n",
    "10. Test drive the implementation support in your platform of choice for data preprocessing phases such as cleaning, selection, transformation, integration in addition to the earlier exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
